{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d28665",
   "metadata": {},
   "source": [
    "## ML2 Classification Project - Heart Disease Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0f555d",
   "metadata": {},
   "source": [
    "Author: Paula Gwanchele\n",
    "\n",
    "Algorithms: Logistic Regression, Random Forest, Neural Net (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708f89a5",
   "metadata": {},
   "source": [
    "### 1) Load Modules + Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1793c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    RocCurveDisplay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18145ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (303, 14)\n",
      "\n",
      "Columns: ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'heart_disease']\n",
      "\n",
      "Head:\n",
      "    age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
      "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
      "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
      "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
      "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
      "\n",
      "    ca  thal  heart_disease  \n",
      "0  0.0   6.0              0  \n",
      "1  3.0   3.0              1  \n",
      "2  2.0   7.0              1  \n",
      "3  0.0   3.0              0  \n",
      "4  0.0   3.0              0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart_disease_medical_data.csv\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nHead:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b30151",
   "metadata": {},
   "source": [
    "### 2) Basic Data Checks + EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44767a3e",
   "metadata": {},
   "source": [
    "Dataset description: 13 columns, 1 target variable\n",
    "- `age` - age in years  \n",
    "- `sex` - sex (1 = male; 0 = female)\n",
    "- `cp`  -   chest pain type\n",
    "        -- Value 1: typical angina\n",
    "        -- Value 2: atypical angina\n",
    "        -- Value 3: non-anginal pain\n",
    "        -- Value 4: asymptomatic\n",
    "- `trestbps` - resting blood pressure (on admission to the hospital)\n",
    "- `chol` -  serum cholestoral in mg/dl\n",
    "- `fbs` -  fasting blood sugar > 120 mg/dl\n",
    "- `restecg` - resting electrocardiographic results\n",
    "- `thalach` - maximum heart rate achieved\n",
    "- `exang` -  exercise induced angina\n",
    "- `oldpeak` -  ST depression induced by exercise relative to rest\n",
    "- `slope` - the slope of the peak exercise ST segment\n",
    "        -- Value 1: upsloping\n",
    "        -- Value 2: flat\n",
    "        -- Value 3: downsloping\n",
    "- `ca` -  number of major vessels (0-3) colored by flourosopy\n",
    "- `thal` - 3 = normal; 6 = fixed defect; 7 = reversable defect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f724f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      " age              0\n",
      "sex              0\n",
      "cp               0\n",
      "trestbps         0\n",
      "chol             0\n",
      "fbs              0\n",
      "restecg          0\n",
      "thalach          0\n",
      "exang            0\n",
      "oldpeak          0\n",
      "slope            0\n",
      "ca               4\n",
      "thal             2\n",
      "heart_disease    0\n",
      "dtype: int64\n",
      "\n",
      "Target distribution:\n",
      " heart_disease\n",
      "0    164\n",
      "1    139\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target distribution (%):\n",
      " heart_disease\n",
      "0    54.1\n",
      "1    45.9\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values per column:\\n\", df.isna().sum())\n",
    "\n",
    "target_col = \"heart_disease\"   # in your CSV it is already binary (0/1)\n",
    "assert target_col in df.columns, f\"Target column '{target_col}' not found.\"\n",
    "\n",
    "print(\"\\nTarget distribution:\\n\", df[target_col].value_counts(dropna=False))\n",
    "print(\"\\nTarget distribution (%):\\n\", df[target_col].value_counts(normalize=True).round(3) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "182793df",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Plot target distribution\n",
    "plt.figure()\n",
    "sns.countplot(x=target_col, data=df)\n",
    "plt.title(\"Target Distribution (0 = No disease, 1 = Disease)\")\n",
    "plt.xlabel(\"heart_disease\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"target_distribution.png\"), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f3bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap (numeric)\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = df.corr(numeric_only=True)\n",
    "sns.heatmap(corr, annot=False)\n",
    "plt.title(\"Correlation Heatmap (numeric features)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"correlation_heatmap.png\"), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3cf6c8",
   "metadata": {},
   "source": [
    "### 3) Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011eda69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nTrain shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a48136",
   "metadata": {},
   "source": [
    "### 4) Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02989884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this heart dataset, columns are numeric codes (still fine as numeric).\n",
    "# We'll treat all as numeric, impute missing, then scale (needed for LR + MLP).\n",
    "numeric_features = X.columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1ecde2",
   "metadata": {},
   "source": [
    "### 5) Models + Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02782906",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    max_iter=2000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Wrap each in a pipeline (like the insurance example style)\n",
    "pipe_lr = Pipeline(steps=[(\"prep\", preprocessor), (\"model\", log_reg)])\n",
    "pipe_rf = Pipeline(steps=[(\"prep\", preprocessor), (\"model\", rf)])\n",
    "pipe_mlp = Pipeline(steps=[(\"prep\", preprocessor), (\"model\", mlp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8fa771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning (GridSearchCV)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "param_grid_lr = {\n",
    "    \"model__C\": [0.01, 0.1, 1, 10],\n",
    "    \"model__penalty\": [\"l2\"],\n",
    "    \"model__solver\": [\"lbfgs\"]\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    \"model__n_estimators\": [200, 500],\n",
    "    \"model__max_depth\": [None, 5, 10],\n",
    "    \"model__min_samples_split\": [2, 5],\n",
    "    \"model__min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "param_grid_mlp = {\n",
    "    \"model__hidden_layer_sizes\": [(32,), (64,), (64, 32)],\n",
    "    \"model__alpha\": [0.0001, 0.001, 0.01],\n",
    "    \"model__learning_rate_init\": [0.001, 0.01]\n",
    "}\n",
    "\n",
    "# We'll optimize for balanced accuracy (good habit if classes are uneven)\n",
    "scoring = \"balanced_accuracy\"\n",
    "\n",
    "grid_lr = GridSearchCV(pipe_lr, param_grid_lr, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "grid_rf = GridSearchCV(pipe_rf, param_grid_rf, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "grid_mlp = GridSearchCV(pipe_mlp, param_grid_mlp, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "print(\"\\nTraining Logistic Regression (GridSearch)...\")\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training Random Forest (GridSearch)...\")\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training MLP Neural Network (GridSearch)...\")\n",
    "grid_mlp.fit(X_train, y_train)\n",
    "\n",
    "best_models = {\n",
    "    \"Logistic Regression\": grid_lr.best_estimator_,\n",
    "    \"Random Forest\": grid_rf.best_estimator_,\n",
    "    \"Neural Net (MLP)\": grid_mlp.best_estimator_\n",
    "}\n",
    "\n",
    "print(\"\\nBest params:\")\n",
    "for name, grid in [(\"LR\", grid_lr), (\"RF\", grid_rf), (\"MLP\", grid_mlp)]:\n",
    "    print(f\"{name}: {grid.best_params_} | best CV balanced_acc={grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54191a57",
   "metadata": {},
   "source": [
    "### 6) Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c3bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # probabilities for ROC-AUC (if available)\n",
    "    y_proba = None\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    bacc = balanced_accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    auc = None\n",
    "    if y_proba is not None:\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"MODEL: {name}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Accuracy:          {acc:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {bacc:.4f}\")\n",
    "    print(f\"Precision:         {prec:.4f}\")\n",
    "    print(f\"Recall:            {rec:.4f}\")\n",
    "    print(f\"F1-score:          {f1:.4f}\")\n",
    "    if auc is not None:\n",
    "        print(f\"ROC-AUC:           {auc:.4f}\")\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1845523",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Save confusion matrix plot\n",
    "    plt.figure()\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"confusion_matrix_{name.replace(' ', '_')}.png\"), dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a288be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Save ROC curve if possible\n",
    "    if y_proba is not None:\n",
    "        plt.figure()\n",
    "        RocCurveDisplay.from_predictions(y_test, y_proba)\n",
    "        plt.title(f\"ROC Curve - {name}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUTPUT_DIR, f\"roc_curve_{name.replace(' ', '_')}.png\"), dpi=200)\n",
    "        plt.show()\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"balanced_accuracy\": bacc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9748ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, StratifiedKFold, GridSearchCV\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "results = []\n",
    "for name, model in best_models.items():\n",
    "    res = evaluate_model(name, model, X_test, y_test)\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"balanced_accuracy\", ascending=False)\n",
    "print(\"\\n=== Summary (sorted by balanced accuracy) ===\\n\", results_df)\n",
    "\n",
    "results_path = os.path.join(OUTPUT_DIR, \"model_results_summary.csv\")\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(\"\\nSaved results to:\", results_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 9) Save a cleaned version of the dataset (optional but good for submission)\n",
    "# -----------------------------\n",
    "clean_path = os.path.join(OUTPUT_DIR, \"heart_disease_cleaned.csv\")\n",
    "df.to_csv(clean_path, index=False)\n",
    "print(\"Saved cleaned dataset to:\", clean_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml2)",
   "language": "python",
   "name": "ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
